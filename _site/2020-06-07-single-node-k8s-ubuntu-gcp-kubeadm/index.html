<!DOCTYPE html>
<html lang="en">
  <!-- Beautiful Jekyll | MIT license | Copyright Dean Attali 2020 -->
  <head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <title>Create single node Kubernetes cluster on Ubuntu using kubeadm on Google Cloud Platform (GCP)</title>
  
  
  <meta name="author" content="Sandeep Kulkarni">
  
  
  

  <link rel="alternate" type="application/rss+xml" title="Kubernetes Tutorials - Kubernetes Tutorials to get you started!" href="http://localhost:4000/feed.xml">

  

  

  


  
    
      
  <link href="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/css/bootstrap.min.css" rel="stylesheet" integrity="sha384-Vkoo8x4CGsO3+Hhxv8T/Q5PaXtkKtu6ug5TOeNV6gBiFeWPGFN9MuhOf23Q9Ifjh" crossorigin="anonymous">


    
      
  <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.12.1/css/all.min.css">


    
      
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic">


    
      
  <link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800">


    
  

  
    
      <link rel="stylesheet" href="/assets/css/bootstrap-social.css">
    
      <link rel="stylesheet" href="/assets/css/main.css">
    
  

  

  

  <!-- Facebook OpenGraph tags -->
  

  
  <meta property="og:title" content="Create single node Kubernetes cluster on Ubuntu using kubeadm on Google Cloud Platform (GCP)">
  

   
  <meta property="og:description" content="In this tutorial, we will try to create single node/control-plane Kubernetes cluster on Ubuntu using kubeadm on Google Cloud Platform (GCP). I will assume you have basic understanding of Docker, Kubernetes and have access to the Google Cloud Platform. Google Cloud Platform SDK Install the Google Cloud SDK Follow the...">
  


  <meta property="og:type" content="website">

  
  <meta property="og:url" content="http://localhost:4000/2020-06-07-single-node-k8s-ubuntu-gcp-kubeadm/">
  <link rel="canonical" href="http://localhost:4000/2020-06-07-single-node-k8s-ubuntu-gcp-kubeadm/">
  

  
  <meta property="og:image" content="http://localhost:4000/assets/img/sk_logo_medium.png">
  


  <!-- Twitter summary cards -->
  <meta name="twitter:card" content="summary">
  <meta name="twitter:site" content="@">
  <meta name="twitter:creator" content="@">

  
  <meta name="twitter:title" content="Create single node Kubernetes cluster on Ubuntu using kubeadm on Google Cloud Platform (GCP)">
  

  
  <meta name="twitter:description" content="In this tutorial, we will try to create single node/control-plane Kubernetes cluster on Ubuntu using kubeadm on Google Cloud Platform (GCP). I will assume you have basic understanding of Docker, Kubernetes and have access to the Google Cloud Platform. Google Cloud Platform SDK Install the Google Cloud SDK Follow the...">
  

  
  <meta name="twitter:image" content="http://localhost:4000/assets/img/sk_logo_medium.png">
  

  

  

</head>


  <body>

    

  
    <nav class="navbar navbar-expand-md navbar-light fixed-top navbar-custom "><a class="navbar-brand" href="http://localhost:4000/">Kubernetes Tutorials</a><button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#main-navbar" aria-controls="main-navbar" aria-expanded="false" aria-label="Toggle navigation">
    <span class="navbar-toggler-icon"></span>
  </button>

  <div class="collapse navbar-collapse" id="main-navbar">
    <ul class="navbar-nav ml-auto">
          <li class="nav-item">
            <a class="nav-link" href="/">Home</a>
          </li>
          <li class="nav-item">
            <a class="nav-link" href="https://sandeepnkulkarni.github.io">About me</a>
          </li></ul>
  </div>

  
    <div class="avatar-container">
      <div class="avatar-img-border">
        <a href="http://localhost:4000/">
          <img alt="Navbar avatar" class="avatar-img" src="/assets/img/sk_logo_medium.png" />
        </a>
      </div>
    </div>
  

</nav>


    <!-- TODO this file has become a mess, refactor it -->







<header class="header-section ">

<div class="intro-header no-img">
  <div class="container-md">
    <div class="row">
      <div class="col-xl-8 offset-xl-2 col-lg-10 offset-lg-1">
        <div class="post-heading">
          <h1>Create single node Kubernetes cluster on Ubuntu using kubeadm on Google Cloud Platform (GCP)</h1>
      
      
      
          <span class="post-meta">Posted on June 7, 2020</span>
          
            <!--- "ReadTime on GitHub Jekyll" (c) 2020 Ruby Griffith Ramirez, MIT License -->






  
  <span class="reader-time post-meta"><span class="d-none d-md-inline middot">&middot;</span> 8 minute read</span>


          
      
        </div>
      </div>
    </div>
  </div>
</div>
</header>





<div class="container-md">
  <div class="row">
    <div class="col-xl-8 offset-xl-2 col-lg-10 offset-lg-1">

      

      <article role="main" class="blog-post">
        <p>In this tutorial, we will try to create single node/control-plane Kubernetes cluster on Ubuntu using kubeadm on Google Cloud Platform (GCP). 
I will assume you have basic understanding of Docker, Kubernetes and have access to the <a href="https://cloud.google.com">Google Cloud Platform</a>.</p>

<h2 id="google-cloud-platform-sdk">Google Cloud Platform SDK</h2>

<h3 id="install-the-google-cloud-sdk">Install the Google Cloud SDK</h3>

<p>Follow the Google Cloud SDK <a href="https://cloud.google.com/sdk/">documentation</a> to install and configure the <code class="language-plaintext highlighter-rouge">gcloud</code> command line utility.</p>

<p>Verify the Google Cloud SDK version is 262.0.0 or higher:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gcloud version
</code></pre></div></div>

<h3 id="set-a-default-compute-region-and-zone">Set a Default Compute Region and Zone</h3>

<p>This tutorial assumes a default compute region and zone have been configured.</p>

<p>If you are using the <code class="language-plaintext highlighter-rouge">gcloud</code> command-line tool for the first time <code class="language-plaintext highlighter-rouge">init</code> is the easiest way to do this:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gcloud init
</code></pre></div></div>

<p>Then be sure to authorize gcloud to access the Cloud Platform with your Google user credentials:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gcloud auth login
</code></pre></div></div>

<p>Next set a default compute region and compute zone:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gcloud config set compute/region us-west1
</code></pre></div></div>

<p>Set a default compute zone:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gcloud config set compute/zone us-west1-c
</code></pre></div></div>

<h3 id="virtual-private-cloud-network">Virtual Private Cloud Network</h3>

<p>In this section a dedicated Virtual Private Cloud (VPC) network will be setup to host the Kubernetes cluster.</p>

<p>Create the k8s-demo custom VPC network:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gcloud compute networks create k8s-network --subnet-mode custom
</code></pre></div></div>
<p>A subnet must be provisioned with an IP address range large enough to assign a private IP address to each node in the Kubernetes cluster.</p>

<p>Create the kubernetes subnet in the k8s-demo VPC network:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gcloud compute networks subnets create kubernetes \
  --network k8s-network \
  --range 10.240.0.0/24
</code></pre></div></div>

<h3 id="firewall-rules">Firewall Rules</h3>

<p>Create a firewall rule that allows internal communication across all protocols:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gcloud compute firewall-rules create k8s-allow-internal \
  --allow tcp,udp,icmp \
  --network k8s-network \
  --source-ranges 10.240.0.0/24,10.200.0.0/16
</code></pre></div></div>
<p>Create a firewall rule that allows external SSH, ICMP, and HTTPS:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gcloud compute firewall-rules create k8s-allow-external \
  --allow tcp:22,tcp:6443,icmp \
  --network k8s-network \
  --source-ranges 0.0.0.0/0
</code></pre></div></div>

<h3 id="compute-instance">Compute Instance</h3>

<p>Create Ubuntu 18.04 compute instance which will host the Kubernetes control plane:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gcloud compute instances create k8s-master \
    --async \
    --boot-disk-size 200GB \
    --can-ip-forward \
    --image-family ubuntu-1804-lts \
    --image-project ubuntu-os-cloud \
    --machine-type n1-standard-2 \
    --private-network-ip 10.240.0.10 \
    --scopes compute-rw,storage-ro,service-management,service-control,logging-write,monitoring \
    --subnet kubernetes \
    --tags kubeadm-test,controller
</code></pre></div></div>

<p>We have chosen n1-standard-2 as machine type instead of n1-standard-1. This is because preflight check in kubeadm does not allow single CPU setup to proceed with installation. You will see below warning instead:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>[init] Using Kubernetes version: v1.18.3
[preflight] Running pre-flight checks
error execution phase preflight: [preflight] Some fatal errors occurred:
        [ERROR NumCPU]: the number of available CPUs 1 is less than the required 2
</code></pre></div></div>

<p>To learn more about recommended hardware and software requirements for <code class="language-plaintext highlighter-rouge">kubeadm</code>, please refer <a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/install-kubeadm/#before-you-begin">kubeadm’s minimum requirements</a>.</p>

<p>After waiting for some time, continue to check if the instance is available with below command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gcloud compute instances list
</code></pre></div></div>

<h3 id="ssh-access">SSH Access</h3>

<p>SSH access to the k8s-master compute instance can be gained by running below command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>gcloud compute ssh k8s-master
</code></pre></div></div>

<h2 id="kubernetes-setup">Kubernetes Setup</h2>

<h3 id="deploy-docker">Deploy Docker</h3>

<p>Install latest Docker container runtime using following command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl -sSL get.docker.com | sh
</code></pre></div></div>

<p>After the installation is finished, add current user to the “docker” group to use Docker as a non-root user with command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo usermod -aG docker $USER
</code></pre></div></div>

<h3 id="enable-support-for-cgroup-swap-limit-capabilities">Enable support for cgroup swap limit capabilities</h3>

<p>There is a need to enable support for cgroup swap limit on Ubuntu 18.04. Otherwise <code class="language-plaintext highlighter-rouge">docker info</code> command will show below warning:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>WARNING: No swap limit support
</code></pre></div></div>

<p>Edit the file /etc/default/grub.d/50-cloudimg-settings.cfg:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo nano /etc/default/grub.d/50-cloudimg-settings.cfg
</code></pre></div></div>

<p>Modify the entry for GRUB_CMDLINE_LINUX_DEFAULT and add cgroup_enable=memory swapaccount=1 like below:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>GRUB_CMDLINE_LINUX_DEFAULT="console=ttyS0 cgroup_enable=memory swapaccount=1"
</code></pre></div></div>

<p>Save the changes and update grub with below command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo update-grub
</code></pre></div></div>

<p>Reboot Kubernetes master server with command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo reboot
</code></pre></div></div>

<p>Verify that grub is correctly updated with <code class="language-plaintext highlighter-rouge">cat /proc/cmdline</code> command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ cat /proc/cmdline
BOOT_IMAGE=/boot/vmlinuz-5.3.0-1020-gcp console=ttyS0 cgroup_enable=memory swapaccount=1
</code></pre></div></div>

<p>Verify that <code class="language-plaintext highlighter-rouge">docker info</code> no longer shows warning.</p>

<h3 id="set-up-the-docker-daemon-options">Set up the Docker daemon options</h3>

<p>Set cgroup driver to systemd and supply other Docker deamon options by creating a new file /etc/docker/daemon.json with below command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat &lt;&lt;EOF | sudo tee /etc/docker/daemon.json
{
  "exec-opts": ["native.cgroupdriver=systemd"],
  "log-driver": "json-file",
  "log-opts": {
    "max-size": "100m"
  },
  "storage-driver": "overlay2"
}
EOF
</code></pre></div></div>

<p>This is a recommendation for using Docker as container runtime with Kubernetes. Refer: https://kubernetes.io/docs/setup/production-environment/container-runtimes/</p>

<h3 id="enable-ip-forwarding">Enable IP forwarding</h3>

<p>Enable IP forwarding by editing /etc/sysctl.conf:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo nano /etc/sysctl.conf
</code></pre></div></div>

<p>and uncomment following line:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>#net.ipv4.ip_forward=1
</code></pre></div></div>

<p>Reboot Kubernetes master server with command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo reboot
</code></pre></div></div>

<p>Verify that <code class="language-plaintext highlighter-rouge">docker info</code> shows updated cgroup driver:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code> Cgroup Driver: systemd
</code></pre></div></div>

<h3 id="deploy-kubernetes-packages">Deploy Kubernetes packages</h3>

<p>Add Kubernetes APT entry into source with command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>cat &lt;&lt;EOF | sudo tee /etc/apt/sources.list.d/kubernetes.list
deb https://apt.kubernetes.io/ kubernetes-xenial main
EOF
</code></pre></div></div>

<p>Install required Kubernetes packages:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>{
  curl -s https://packages.cloud.google.com/apt/doc/apt-key.gpg | sudo apt-key add -
  sudo apt update
  sudo apt install -y kubeadm kubectl kubelet
  sudo apt-mark hold kubelet kubeadm kubectl
}
</code></pre></div></div>

<h3 id="initialize-kubernetes">Initialize Kubernetes</h3>

<p>Run following command to start creation of Kubernetes cluster:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>sudo kubeadm init --pod-network-cidr=10.244.0.0/16
</code></pre></div></div>

<p>Sample output:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ sudo kubeadm init --pod-network-cidr=10.244.0.0/16
W0529 07:01:50.387903    2395 configset.go:202] WARNING: kubeadm cannot validate component configs for API groups [kubelet.config.k8s.io kubeproxy.config.k8s.io]
[init] Using Kubernetes version: v1.18.3
[preflight] Running pre-flight checks
[preflight] Pulling images required for setting up a Kubernetes cluster
[preflight] This might take a minute or two, depending on the speed of your internet connection
[preflight] You can also perform this action in beforehand using 'kubeadm config images pull'
[kubelet-start] Writing kubelet environment file with flags to file "/var/lib/kubelet/kubeadm-flags.env"
[kubelet-start] Writing kubelet configuration to file "/var/lib/kubelet/config.yaml"
[kubelet-start] Starting the kubelet
[certs] Using certificateDir folder "/etc/kubernetes/pki"
[certs] Generating "ca" certificate and key
[certs] Generating "apiserver" certificate and key
[certs] apiserver serving cert is signed for DNS names [k8s-master kubernetes kubernetes.default kubernetes.default.svc kubernetes.default.svc.cluster.local] and IPs [10.96.0.1 10.240.0.10]
[certs] Generating "apiserver-kubelet-client" certificate and key
[certs] Generating "front-proxy-ca" certificate and key
[certs] Generating "front-proxy-client" certificate and key
[certs] Generating "etcd/ca" certificate and key
[certs] Generating "etcd/server" certificate and key
[certs] etcd/server serving cert is signed for DNS names [k8s-master localhost] and IPs [10.240.0.10 127.0.0.1 ::1]
[certs] Generating "etcd/peer" certificate and key
[certs] etcd/peer serving cert is signed for DNS names [k8s-master localhost] and IPs [10.240.0.10 127.0.0.1 ::1]
[certs] Generating "etcd/healthcheck-client" certificate and key
[certs] Generating "apiserver-etcd-client" certificate and key
[certs] Generating "sa" key and public key
[kubeconfig] Using kubeconfig folder "/etc/kubernetes"
[kubeconfig] Writing "admin.conf" kubeconfig file
[kubeconfig] Writing "kubelet.conf" kubeconfig file
[kubeconfig] Writing "controller-manager.conf" kubeconfig file
[kubeconfig] Writing "scheduler.conf" kubeconfig file
[control-plane] Using manifest folder "/etc/kubernetes/manifests"
[control-plane] Creating static Pod manifest for "kube-apiserver"
[control-plane] Creating static Pod manifest for "kube-controller-manager"
W0529 07:02:20.596935    2395 manifests.go:225] the default kube-apiserver authorization-mode is "Node,RBAC"; using "Node,RBAC"
[control-plane] Creating static Pod manifest for "kube-scheduler"
W0529 07:02:20.598850    2395 manifests.go:225] the default kube-apiserver authorization-mode is "Node,RBAC"; using "Node,RBAC"
[etcd] Creating static Pod manifest for local etcd in "/etc/kubernetes/manifests"
[wait-control-plane] Waiting for the kubelet to boot up the control plane as static Pods from directory "/etc/kubernetes/manifests". This can take up to 4m0s
[apiclient] All control plane components are healthy after 19.002634 seconds
[upload-config] Storing the configuration used in ConfigMap "kubeadm-config" in the "kube-system" Namespace
[kubelet] Creating a ConfigMap "kubelet-config-1.18" in namespace kube-system with the configuration for the kubelets in the cluster
[upload-certs] Skipping phase. Please see --upload-certs
[mark-control-plane] Marking the node k8s-master as control-plane by adding the label "node-role.kubernetes.io/master=''"
[mark-control-plane] Marking the node k8s-master as control-plane by adding the taints [node-role.kubernetes.io/master:NoSchedule]
[bootstrap-token] Using token: qime8q.8mpf97fdxxxxxxxx
[bootstrap-token] Configuring bootstrap tokens, cluster-info ConfigMap, RBAC Roles
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to get nodes
[bootstrap-token] configured RBAC rules to allow Node Bootstrap tokens to post CSRs in order for nodes to get long term certificate credentials
[bootstrap-token] configured RBAC rules to allow the csrapprover controller automatically approve CSRs from a Node Bootstrap Token
[bootstrap-token] configured RBAC rules to allow certificate rotation for all node client certificates in the cluster
[bootstrap-token] Creating the "cluster-info" ConfigMap in the "kube-public" namespace
[kubelet-finalize] Updating "/etc/kubernetes/kubelet.conf" to point to a rotatable kubelet client certificate and key
[addons] Applied essential addon: CoreDNS
[addons] Applied essential addon: kube-proxy

Your Kubernetes control-plane has initialized successfully!

To start using your cluster, you need to run the following as a regular user:

  mkdir -p $HOME/.kube
  sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
  sudo chown $(id -u):$(id -g) $HOME/.kube/config

You should now deploy a pod network to the cluster.
Run "kubectl apply -f [podnetwork].yaml" with one of the options listed at:
  https://kubernetes.io/docs/concepts/cluster-administration/addons/

Then you can join any number of worker nodes by running the following on each as root:

kubeadm join 10.240.0.10:6443 --token qime8q.8mpf97fdxxxxxxxx \
    --discovery-token-ca-cert-hash sha256:8f61ee1955f194f6cc7a6888baf37447b29a86a93b214205154a8abdxxxxxxxx
</code></pre></div></div>

<p>As mentioned in the output, we need to run the commands shown below to allow us to use Kubernetes:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>mkdir -p $HOME/.kube
sudo cp -i /etc/kubernetes/admin.conf $HOME/.kube/config
sudo chown $(id -u):$(id -g) $HOME/.kube/config
</code></pre></div></div>

<p>To use Flannel as a pod network, run following command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
</code></pre></div></div>

<p>Sample output:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl apply -f https://raw.githubusercontent.com/coreos/flannel/master/Documentation/kube-flannel.yml
podsecuritypolicy.policy/psp.flannel.unprivileged created
clusterrole.rbac.authorization.k8s.io/flannel created
clusterrolebinding.rbac.authorization.k8s.io/flannel created
serviceaccount/flannel created
configmap/kube-flannel-cfg created
daemonset.apps/kube-flannel-ds-amd64 created
daemonset.apps/kube-flannel-ds-arm64 created
daemonset.apps/kube-flannel-ds-arm created
daemonset.apps/kube-flannel-ds-ppc64le created
daemonset.apps/kube-flannel-ds-s390x created
</code></pre></div></div>

<p>Verify that all pods are healthy by running below command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl get pods --all-namespaces -o wide
</code></pre></div></div>

<p>Sample output:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl get pods --all-namespaces -o wide
NAMESPACE     NAME                                 READY   STATUS    RESTARTS   AGE     IP            NODE         NOMINATED NODE   READINESS GATES
kube-system   coredns-66bff467f8-94knl             1/1     Running   0          3m30s   10.244.0.3    k8s-master   &lt;none&gt;           &lt;none&gt;
kube-system   coredns-66bff467f8-qxhpm             1/1     Running   0          3m30s   10.244.0.2    k8s-master   &lt;none&gt;           &lt;none&gt;
kube-system   etcd-k8s-master                      1/1     Running   0          3m46s   10.240.0.10   k8s-master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-apiserver-k8s-master            1/1     Running   0          3m46s   10.240.0.10   k8s-master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-controller-manager-k8s-master   1/1     Running   0          3m46s   10.240.0.10   k8s-master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-flannel-ds-amd64-cbg6m          1/1     Running   0          81s     10.240.0.10   k8s-master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-proxy-sjwt6                     1/1     Running   0          3m30s   10.240.0.10   k8s-master   &lt;none&gt;           &lt;none&gt;
kube-system   kube-scheduler-k8s-master            1/1     Running   0          3m46s   10.240.0.10   k8s-master   &lt;none&gt;           &lt;none&gt;
</code></pre></div></div>

<p>By default, your cluster will not schedule Pods on the control-plane node for security reasons. Allow master/controller to schedule pods by running below command:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl taint nodes --all node-role.kubernetes.io/master-
</code></pre></div></div>

<p>Sample output:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>$ kubectl taint nodes --all node-role.kubernetes.io/master-
node/k8s-master untainted
</code></pre></div></div>

<p>After this, the scheduler will then be able to schedule Pods everywhere.</p>

<p>Unless this is done, any pod deployments will not run on this master. Example output from describe pod where master node has taint:</p>

<div class="language-plaintext highlighter-rouge"><div class="highlight"><pre class="highlight"><code>Events:
  Type     Reason            Age                  From                   Message
  ----     ------            ----                 ----                   -------
  Warning  FailedScheduling  87s (x3 over 2m27s)  default-scheduler      0/1 nodes are available: 1 node(s) had taint {node-role.kubernetes.io/master: }, that the pod didn't tolerate.
  Normal   Pulling           81s                  kubelet, k8s-master    Pulling image "k8s.gcr.io/echoserver:1.4"
  Normal   Pulled            76s                  kubelet, k8s-master    Successfully pulled image "k8s.gcr.io/echoserver:1.4"
  Normal   Created           74s                  kubelet, k8s-master    Created container echoserver
  Normal   Started           74s                  kubelet, k8s-master    Started container echoserver
</code></pre></div></div>

<h3 id="related-links">Related links:</h3>

<ul>
  <li><a href="02-add-worker-node.md">Add worker node to Kubernetes Cluster</a></li>
  <li><a href="03-reset-kubernetes-cluster.md">Reset Kubernetes Cluster</a></li>
</ul>

<h3 id="references">References</h3>

<ul>
  <li><a href="https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/">https://kubernetes.io/docs/setup/production-environment/tools/kubeadm/create-cluster-kubeadm/</a></li>
  <li><a href="https://github.com/kelseyhightower/kubernetes-the-hard-way">https://github.com/kelseyhightower/kubernetes-the-hard-way</a></li>
  <li><a href="https://wiki.learnlinux.tv/index.php/How_to_build_your_own_Raspberry_Pi_Kubernetes_Cluster#Install_flannel_network_driver">https://wiki.learnlinux.tv/index.php/How_to_build_your_own_Raspberry_Pi_Kubernetes_Cluster#Install_flannel_network_driver</a></li>
  <li><a href="https://phoenixnap.com/kb/install-kubernetes-on-ubuntu">https://phoenixnap.com/kb/install-kubernetes-on-ubuntu</a></li>
</ul>

      </article>

      
        <div class="blog-tags">
          Tags:
          
          
            <a href="/tags#kubernetes">kubernetes</a>
          
            <a href="/tags#kubeadm">kubeadm</a>
          
            <a href="/tags#cluster">cluster</a>
          
            <a href="/tags#gcp">gcp</a>
          
            <a href="/tags#ubuntu">ubuntu</a>
          
          
        </div>
      

      
        <!-- Check if any share-links are active -->





      

      <ul class="pagination blog-pager">
        
        
        <li class="page-item next">
          <a class="page-link" href="/2020-06-07-add-worker-node/" data-toggle="tooltip" data-placement="top" title="Add worker node to Kubernetes Cluster">Next Post &rarr;</a>
        </li>
        
      </ul>
              
  
  
  

  



    </div>
  </div>
</div>


    <footer>
  <div class="container-md beautiful-jekyll-footer">
    <div class="row">
      <div class="col-xl-8 offset-xl-2 col-lg-10 offset-lg-1">
      <ul class="list-inline text-center footer-links"><li class="list-inline-item">
    <a href="/feed.xml" title="RSS">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fas fa-rss fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">RSS</span>
    </a>
  </li><li class="list-inline-item">
    <a href="https://github.com/sandeepnkulkarni" title="GitHub">
      <span class="fa-stack fa-lg" aria-hidden="true">
        <i class="fas fa-circle fa-stack-2x"></i>
        <i class="fab fa-github fa-stack-1x fa-inverse"></i>
      </span>
      <span class="sr-only">GitHub</span>
   </a>
  </li></ul>

      
      <p class="copyright text-muted">
      
        Sandeep Kulkarni
        &nbsp;&bull;&nbsp;
      
      2020

      
        &nbsp;&bull;&nbsp;
        <a href="http://localhost:4000/">https://sandeepnkulkarni.github.io</a>
      

      
      </p>
      <!-- Please don't remove this, keep my open source work credited :) -->
      <p class="theme-by text-muted">
        Theme by
        <a href="https://beautifuljekyll.com">beautiful-jekyll</a>
      </p>
      </div>
    </div>
  </div>
</footer>

  
    
  
    
  <script src="https://code.jquery.com/jquery-3.4.1.min.js" integrity="sha256-CSXorXvZcTkaix6Yvo6HppcZGetbYMGWSFlBw8HfCJo=" crossorigin="anonymous"></script>


  
    
  <script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.0/dist/umd/popper.min.js" integrity="sha384-Q6E9RHvbIyZFJoft+2mJbHaEWldlvI9IOYy5n3zV9zzTtmI3UksdQRVvoxMfooAo" crossorigin="anonymous"></script>


  
    
  <script src="https://stackpath.bootstrapcdn.com/bootstrap/4.4.1/js/bootstrap.min.js" integrity="sha384-wfSDF2E50Y2D1uUdj0O3uMBJnjuUD4Ih7YwaYd1iqfktj0Uod8GCExl3Og8ifwB6" crossorigin="anonymous"></script>


  



  
    <!-- doing something a bit funky here because I want to be careful not to include JQuery twice! -->
    
      <script src="/assets/js/main.js"></script>
    
  






  
  </body>
</html>
